{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NetCDF to GeoTIFF Converter\n",
    "\n",
    "This notebook converts NetCDF files to GeoTIFF format for easier processing with standard GIS tools.\n",
    "\n",
    "**Use cases:**\n",
    "- Converting PM2.5 NetCDF data to TIFFs\n",
    "- Processing climate/atmospheric data\n",
    "- Batch conversion of time-series NetCDF files\n",
    "\n",
    "**Requirements:**\n",
    "- `xarray`: For reading NetCDF files\n",
    "- `rioxarray`: For spatial reference handling and GeoTIFF export\n",
    "- `netCDF4`: NetCDF backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your input/output paths and NetCDF variable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/data/00_source/archives/pm25/2019\n",
      "Output directory: /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/data/temp/pm25_tiffs\n",
      "Target CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "project_root = Path.cwd().parent\n",
    "DATA_ROOT = project_root.parent / \"data\"\n",
    "\n",
    "# Input: Directory containing NetCDF files or single NetCDF file\n",
    "INPUT_PATH = DATA_ROOT / \"00_source\" / \"archives\" / \"pm25\" /\"2019\" # NC files location\n",
    "\n",
    "# Output: Directory to save GeoTIFFs\n",
    "OUTPUT_DIR = DATA_ROOT / \"temp\" / \"pm25_tiffs\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NetCDF variable settings\n",
    "VARIABLE_NAME = None  # Set to specific variable name, or None to auto-detect\n",
    "CRS = \"EPSG:4326\"  # Default coordinate reference system (WGS84)\n",
    "\n",
    "# Dimension names (update if your NetCDF uses different names)\n",
    "X_DIM = \"lon\"  # or \"longitude\", \"x\"\n",
    "Y_DIM = \"lat\"  # or \"latitude\", \"y\"\n",
    "TIME_DIM = \"time\"  # or None if no time dimension\n",
    "\n",
    "print(f\"Input path: {INPUT_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Target CRS: {CRS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-header",
   "metadata": {},
   "source": [
    "## Step 1: Explore NetCDF Structure\n",
    "\n",
    "First, let's examine a sample NetCDF file to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "explore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 NetCDF file(s)\n",
      "  - V6GL02.04.CNNPM25.GL.201901-201901.nc\n",
      "  - V6GL02.04.CNNPM25.GL.201902-201902.nc\n",
      "  - V6GL02.04.CNNPM25.GL.201903-201903.nc\n",
      "  - V6GL02.04.CNNPM25.GL.201904-201904.nc\n",
      "  - V6GL02.04.CNNPM25.GL.201905-201905.nc\n",
      "  ... and 7 more\n"
     ]
    }
   ],
   "source": [
    "# Find NetCDF files\n",
    "if INPUT_PATH.is_file():\n",
    "    nc_files = [INPUT_PATH]\n",
    "else:\n",
    "    nc_files = sorted(list(INPUT_PATH.rglob(\"*.nc\")) + list(INPUT_PATH.rglob(\"*.nc4\")))\n",
    "\n",
    "print(f\"Found {len(nc_files)} NetCDF file(s)\")\n",
    "if nc_files:\n",
    "    for f in nc_files[:5]:\n",
    "        print(f\"  - {f.name}\")\n",
    "    if len(nc_files) > 5:\n",
    "        print(f\"  ... and {len(nc_files) - 5} more\")\n",
    "else:\n",
    "    print(\"⚠ No NetCDF files found. Please check INPUT_PATH.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting: V6GL02.04.CNNPM25.GL.201901-201901.nc\n",
      "======================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "<xarray.Dataset> Size: 2GB\n",
      "Dimensions:  (lat: 13000, lon: 36000)\n",
      "Coordinates:\n",
      "  * lat      (lat) float32 52kB -59.99 -59.99 -59.97 -59.97 ... 69.97 69.99 70.0\n",
      "  * lon      (lon) float32 144kB -180.0 -180.0 -180.0 ... 180.0 180.0 180.0\n",
      "Data variables:\n",
      "    PM25     (lat, lon) float32 2GB ...\n",
      "Attributes:\n",
      "    TITLE:            Convolutional Neural Network Monthly PM2.5 Estimation o...\n",
      "    CONTACT:          SIYUAN SHEN <s.siyuan@wustl.edu>\n",
      "    LAT_DELTA:        0.01\n",
      "    LON_DELTA:        0.01\n",
      "    SPATIALCOVERAGE:  GL\n",
      "    TIMECOVERAGE:     201901\n",
      "\n",
      "======================================================================\n",
      "Data Variables:\n",
      "  - PM25: ('lat', 'lon') (13000, 36000) (float32)\n",
      "\n",
      "Coordinates:\n",
      "  - lat: (13000,)\n",
      "  - lon: (36000,)\n",
      "\n",
      "Attributes:\n",
      "  - TITLE: Convolutional Neural Network Monthly PM2.5 Estimation over GL Area. (0.01x0.01 resolution)\n",
      "  - CONTACT: SIYUAN SHEN <s.siyuan@wustl.edu>\n",
      "  - LAT_DELTA: 0.01\n",
      "  - LON_DELTA: 0.01\n",
      "  - SPATIALCOVERAGE: GL\n",
      "  - TIMECOVERAGE: 201901\n"
     ]
    }
   ],
   "source": [
    "# Inspect first NetCDF file\n",
    "if nc_files:\n",
    "    sample_file = nc_files[0]\n",
    "    print(f\"Inspecting: {sample_file.name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    with xr.open_dataset(sample_file) as ds:\n",
    "        print(\"\\nDataset Overview:\")\n",
    "        print(ds)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"Data Variables:\")\n",
    "        for var in ds.data_vars:\n",
    "            print(f\"  - {var}: {ds[var].dims} {ds[var].shape} ({ds[var].dtype})\")\n",
    "        \n",
    "        print(\"\\nCoordinates:\")\n",
    "        for coord in ds.coords:\n",
    "            print(f\"  - {coord}: {ds[coord].shape}\")\n",
    "        \n",
    "        print(\"\\nAttributes:\")\n",
    "        for attr, value in ds.attrs.items():\n",
    "            print(f\"  - {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convert-header",
   "metadata": {},
   "source": [
    "## Step 2: Convert NetCDF to GeoTIFF\n",
    "\n",
    "Convert each NetCDF file (or time slice) to GeoTIFF format.\n",
    "\n",
    "**Important Note on Data Orientation:**  \n",
    "Many NetCDF files (especially climate/atmospheric data like PM2.5) store latitude coordinates in **descending order** (90° to -90° instead of -90° to 90°). This causes images to be rendered **upside down** (south at top, north at bottom), which **breaks spatial operations** like clipping to country boundaries.\n",
    "\n",
    "The conversion function below automatically detects and corrects this issue by:\n",
    "1. Checking if Y-coordinates are in descending order\n",
    "2. Flipping the Y-axis using `sortby()` to ensure proper orientation\n",
    "3. Confirming the correction in the console output\n",
    "\n",
    "You'll see messages like `\"⚠ Detected descending Y-axis\"` followed by `\"✓ Y-axis corrected\"` if this fix is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convert-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conversion function defined\n"
     ]
    }
   ],
   "source": [
    "def convert_netcdf_to_geotiff(\n",
    "    nc_path: Path,\n",
    "    output_dir: Path,\n",
    "    variable_name: str = None,\n",
    "    crs: str = \"EPSG:4326\",\n",
    "    x_dim: str = \"lon\",\n",
    "    y_dim: str = \"lat\",\n",
    "    time_dim: str = \"time\"\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Convert NetCDF file to GeoTIFF(s).\n",
    "    \n",
    "    If the NetCDF has a time dimension, creates one GeoTIFF per time step.\n",
    "    Otherwise, creates a single GeoTIFF.\n",
    "    \n",
    "    Returns:\n",
    "        List of created GeoTIFF file paths\n",
    "    \"\"\"\n",
    "    output_files = []\n",
    "    \n",
    "    with xr.open_dataset(nc_path) as ds:\n",
    "        # Auto-detect variable if not specified\n",
    "        if variable_name is None:\n",
    "            # Get first data variable\n",
    "            data_vars = list(ds.data_vars)\n",
    "            if not data_vars:\n",
    "                raise ValueError(f\"No data variables found in {nc_path}\")\n",
    "            variable_name = data_vars[0]\n",
    "            print(f\"  Auto-detected variable: {variable_name}\")\n",
    "        \n",
    "        # Get the data array\n",
    "        da = ds[variable_name]\n",
    "        \n",
    "        # FIX FOR UPSIDE-DOWN IMAGES:\n",
    "        # Many NetCDF files (especially climate/atmospheric data) have latitude coordinates\n",
    "        # in descending order (90 to -90 instead of -90 to 90). This causes images to be\n",
    "        # rendered upside down (south at top, north at bottom), which breaks spatial operations\n",
    "        # like clipping. We need to flip the Y-axis if latitudes are descending.\n",
    "        if y_dim in da.coords:\n",
    "            y_coords = da.coords[y_dim].values\n",
    "            # Check if Y coordinates are in descending order (e.g., 90, 89, 88... -> -90)\n",
    "            if len(y_coords) > 1 and y_coords[0] > y_coords[-1]:\n",
    "                print(f\"  ⚠ Detected descending Y-axis (upside-down data)\")\n",
    "                print(f\"    Y range: {y_coords[0]:.2f} to {y_coords[-1]:.2f}\")\n",
    "                print(f\"  → Flipping Y-axis to correct orientation...\")\n",
    "                # Reverse the Y dimension to get ascending order\n",
    "                da = da.sortby(y_dim)\n",
    "                print(f\"  ✓ Y-axis corrected: {da.coords[y_dim].values[0]:.2f} to {da.coords[y_dim].values[-1]:.2f}\")\n",
    "        \n",
    "        # Set spatial dimensions\n",
    "        da = da.rename({x_dim: 'x', y_dim: 'y'} if x_dim in da.dims else {})\n",
    "        \n",
    "        # Assign CRS if not present\n",
    "        if not hasattr(da, 'rio'):\n",
    "            da = da.rio.write_crs(crs)\n",
    "        elif da.rio.crs is None:\n",
    "            da = da.rio.write_crs(crs)\n",
    "        \n",
    "        # Check if there's a time dimension\n",
    "        has_time = time_dim in da.dims\n",
    "        \n",
    "        if has_time:\n",
    "            # Process each time step\n",
    "            time_steps = da[time_dim].values\n",
    "            print(f\"  Processing {len(time_steps)} time steps...\")\n",
    "            \n",
    "            for i, time_val in enumerate(tqdm(time_steps, desc=f\"  {nc_path.name}\")):\n",
    "                # Select single time step\n",
    "                da_time = da.sel({time_dim: time_val})\n",
    "                \n",
    "                # Create output filename\n",
    "                time_str = str(time_val).replace(':', '-').replace(' ', '_')\n",
    "                if 'T' in time_str:\n",
    "                    time_str = time_str.split('T')[0]  # Keep just the date\n",
    "                \n",
    "                output_file = output_dir / f\"{nc_path.stem}_{time_str}.tif\"\n",
    "                \n",
    "                # Write to GeoTIFF\n",
    "                da_time.rio.to_raster(output_file, driver=\"GTiff\", compress=\"lzw\")\n",
    "                output_files.append(output_file)\n",
    "        else:\n",
    "            # Single time step or no time dimension\n",
    "            output_file = output_dir / f\"{nc_path.stem}.tif\"\n",
    "            da.rio.to_raster(output_file, driver=\"GTiff\", compress=\"lzw\")\n",
    "            output_files.append(output_file)\n",
    "            print(f\"  ✓ Created: {output_file.name}\")\n",
    "    \n",
    "    return output_files\n",
    "\n",
    "print(\"✓ Conversion function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "batch-convert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting NetCDF files to GeoTIFF...\n",
      "======================================================================\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201901-201901.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201901-201901.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201902-201902.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201902-201902.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201903-201903.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201903-201903.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201904-201904.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201904-201904.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201905-201905.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201905-201905.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201906-201906.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201906-201906.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201907-201907.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201907-201907.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201908-201908.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201908-201908.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201909-201909.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201909-201909.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201910-201910.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201910-201910.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201911-201911.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201911-201911.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "V6GL02.04.CNNPM25.GL.201912-201912.nc:\n",
      "  Auto-detected variable: PM25\n",
      "  ✓ Created: V6GL02.04.CNNPM25.GL.201912-201912.tif\n",
      "  ✓ Created 1 GeoTIFF file(s)\n",
      "\n",
      "======================================================================\n",
      "✓ Conversion complete!\n",
      "Total GeoTIFF files created: 12\n",
      "Output directory: /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/data/temp/pm25_tiffs\n"
     ]
    }
   ],
   "source": [
    "# Convert all NetCDF files\n",
    "print(\"Converting NetCDF files to GeoTIFF...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_output_files = []\n",
    "\n",
    "for nc_file in nc_files:\n",
    "    print(f\"\\n{nc_file.name}:\")\n",
    "    try:\n",
    "        output_files = convert_netcdf_to_geotiff(\n",
    "            nc_path=nc_file,\n",
    "            output_dir=OUTPUT_DIR,\n",
    "            variable_name=VARIABLE_NAME,\n",
    "            crs=CRS,\n",
    "            x_dim=X_DIM,\n",
    "            y_dim=Y_DIM,\n",
    "            time_dim=TIME_DIM\n",
    "        )\n",
    "        all_output_files.extend(output_files)\n",
    "        print(f\"  ✓ Created {len(output_files)} GeoTIFF file(s)\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"✓ Conversion complete!\")\n",
    "print(f\"Total GeoTIFF files created: {len(all_output_files)}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## Step 3: Verify Output\n",
    "\n",
    "Check the created GeoTIFF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verify",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created GeoTIFF files:\n",
      "  - V6GL02.04.CNNPM25.GL.201901-201901.tif (734.4 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201902-201902.tif (733.0 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201903-201903.tif (731.6 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201904-201904.tif (731.4 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201905-201905.tif (733.5 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201906-201906.tif (734.8 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201907-201907.tif (736.1 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201908-201908.tif (734.3 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201909-201909.tif (733.5 MB)\n",
      "  - V6GL02.04.CNNPM25.GL.201910-201910.tif (733.4 MB)\n",
      "  ... and 2 more\n",
      "\n",
      "Inspecting first GeoTIFF: V6GL02.04.CNNPM25.GL.201901-201901.tif\n",
      "======================================================================\n",
      "Dimensions: 36000 x 13000\n",
      "Bands: 1\n",
      "CRS: EPSG:4326\n",
      "Bounds: BoundingBox(left=-179.99999511705187, bottom=70.00000274664657, right=179.99999511705187, top=-59.99999893194933)\n",
      "Data type: float32\n",
      "NoData value: None\n",
      "\n",
      "Data statistics:\n",
      "  Min: -999.9000\n",
      "  Max: 605.0477\n",
      "  Mean: -624.7463\n",
      "  Std: 490.0598\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "\n",
    "if all_output_files:\n",
    "    # Show sample of created files\n",
    "    print(\"Created GeoTIFF files:\")\n",
    "    for f in all_output_files[:10]:\n",
    "        size_mb = f.stat().st_size / (1024**2)\n",
    "        print(f\"  - {f.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    if len(all_output_files) > 10:\n",
    "        print(f\"  ... and {len(all_output_files) - 10} more\")\n",
    "    \n",
    "    # Inspect first file\n",
    "    print(f\"\\nInspecting first GeoTIFF: {all_output_files[0].name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    with rasterio.open(all_output_files[0]) as src:\n",
    "        print(f\"Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"Bands: {src.count}\")\n",
    "        print(f\"CRS: {src.crs}\")\n",
    "        print(f\"Bounds: {src.bounds}\")\n",
    "        print(f\"Data type: {src.dtypes[0]}\")\n",
    "        print(f\"NoData value: {src.nodata}\")\n",
    "        \n",
    "        # Read and show statistics\n",
    "        data = src.read(1)\n",
    "        valid_data = data[data != src.nodata] if src.nodata is not None else data\n",
    "        \n",
    "        print(f\"\\nData statistics:\")\n",
    "        print(f\"  Min: {np.min(valid_data):.4f}\")\n",
    "        print(f\"  Max: {np.max(valid_data):.4f}\")\n",
    "        print(f\"  Mean: {np.mean(valid_data):.4f}\")\n",
    "        print(f\"  Std: {np.std(valid_data):.4f}\")\n",
    "else:\n",
    "    print(\"No files were created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-header",
   "metadata": {},
   "source": [
    "## Step 4: Quick Visualization (Optional)\n",
    "\n",
    "Visualize one of the converted GeoTIFFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nfrom rasterio.plot import show as rioshow\n\nif all_output_files:\n    # Visualize first file\n    with rasterio.open(all_output_files[0]) as src:\n        fig, ax = plt.subplots(figsize=(12, 8))\n        \n        # Use rasterio.plot.show() which handles geospatial orientation correctly\n        # This ensures the image is displayed right-side up with proper georeferencing\n        rioshow(src, ax=ax, cmap='viridis')\n        \n        ax.set_title(f\"{all_output_files[0].name}\", fontsize=14, fontweight='bold')\n        plt.tight_layout()\n        plt.show()\n        \n        # Also show data statistics\n        data = src.read(1)\n        if src.nodata is not None:\n            valid_data = data[data != src.nodata]\n        else:\n            valid_data = data\n        \n        print(f\"\\nData range: {valid_data.min():.2f} to {valid_data.max():.2f}\")\n        print(f\"Mean: {valid_data.mean():.2f}\")\nelse:\n    print(\"No files to visualize.\")"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Your NetCDF files have been converted to GeoTIFF format and are ready for further processing with geoworkflow or other GIS tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONVERSION SUMMARY\n",
      "======================================================================\n",
      "Input NetCDF files: 12\n",
      "Output GeoTIFF files: 12\n",
      "Output location: /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/data/temp/pm25_tiffs\n",
      "Total size: 8806.6 MB\n",
      "\n",
      "Next steps:\n",
      "  1. Use these GeoTIFFs with geoworkflow processors\n",
      "  2. Clip to country boundaries using spatial/clipper\n",
      "  3. Compute temporal statistics with temporal_raster_utils\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CONVERSION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Input NetCDF files: {len(nc_files)}\")\n",
    "print(f\"Output GeoTIFF files: {len(all_output_files)}\")\n",
    "print(f\"Output location: {OUTPUT_DIR}\")\n",
    "\n",
    "if all_output_files:\n",
    "    total_size = sum(f.stat().st_size for f in all_output_files) / (1024**2)\n",
    "    print(f\"Total size: {total_size:.1f} MB\")\n",
    "    print(f\"\\nNext steps:\")\n",
    "    print(f\"  1. Use these GeoTIFFs with geoworkflow processors\")\n",
    "    print(f\"  2. Clip to country boundaries using spatial/clipper\")\n",
    "    print(f\"  3. Compute temporal statistics with temporal_raster_utils\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoworkflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}