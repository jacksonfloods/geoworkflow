{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f297e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "AfricaPolis Workflow Demonstration Script\n",
    "========================================\n",
    "\n",
    "This script demonstrates the core GeoWorkflow pipeline for processing PM2.5 air quality\n",
    "data and AFRICAPOLIS urban boundary data. The workflow transforms raw geospatial data\n",
    "into analysis-ready enriched datasets through three key stages:\n",
    "\n",
    "1. Spatial Clipping: Extract data for specific countries from global datasets\n",
    "2. Raster Alignment: Ensure all raster data shares consistent spatial properties  \n",
    "3. Statistical Enrichment: Calculate zonal statistics for urban areas\n",
    "\n",
    "Target countries: Togo, Ghana, Tanzania, Kenya\n",
    "Input data: PM2.5 concentrations, AFRICAPOLIS urban boundaries\n",
    "Output: Enriched urban areas with air quality statistics\n",
    "\n",
    "Run this script from the project root directory with the geoworkflow environment activated.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "\n",
    "# Add project source to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "try:\n",
    "    from geoworkflow.processors.aoi.processor import AOIProcessor\n",
    "    from geoworkflow.processors.spatial.clipper import ClippingProcessor\n",
    "    from geoworkflow.processors.spatial.aligner import AlignmentProcessor\n",
    "    from geoworkflow.processors.integration.enrichment import StatisticalEnrichmentProcessor\n",
    "    from geoworkflow.schemas.config_models import (\n",
    "        AOIConfig, ClippingConfig, AlignmentConfig, StatisticalEnrichmentConfig\n",
    "    )\n",
    "    from geoworkflow.core.logging_setup import setup_logging\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing GeoWorkflow modules: {e}\")\n",
    "    print(\"Please ensure you're running from the project root with the correct environment activated.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5407f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:21:02,677 - geoworkflow - INFO - === Starting AfricaPolis Workflow Demonstration ===\n",
      "2025-09-10 19:21:02,681 - geoworkflow - INFO - All required input files found - ready to begin processing\n"
     ]
    }
   ],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"\n",
    "    Initialize logging and verify that all required input files exist.\n",
    "    This function ensures we have a clean starting point for the demonstration.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure logging to show processing steps clearly\n",
    "    logger = setup_logging(level=\"INFO\", log_file=\"notebooks/demo_processing.log\")\n",
    "    logger.info(\"=== Starting AfricaPolis Workflow Demonstration ===\")\n",
    "    \n",
    "    # Define file paths based on the project structure\n",
    "    input_paths = {\n",
    "        \"boundaries\": project_root / \"data\" / \"00_source\" / \"boundaries\" / \"africa_boundaries.geojson\",\n",
    "        \"africapolis\": project_root / \"data\" / \"01_extracted\" / \"AFRICAPOLIS2020.geojson\", \n",
    "        \"pm25_data\": project_root / \"data\" / \"01_extracted\" / \"pm25\" / \"V6GL02_04_CNNPM25_GL_202201-202212_corrected.tif\"\n",
    "    }\n",
    "    \n",
    "    # Verify all required input files are available\n",
    "    missing_files = []\n",
    "    for file_type, file_path in input_paths.items():\n",
    "        if not file_path.exists():\n",
    "            missing_files.append(f\"{file_type}: {file_path}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        logger.error(\"Missing required input files:\")\n",
    "        for missing in missing_files:\n",
    "            logger.error(f\"  - {missing}\")\n",
    "        raise FileNotFoundError(\"Cannot proceed without required input data\")\n",
    "    \n",
    "    logger.info(\"All required input files found - ready to begin processing\")\n",
    "    return logger, input_paths\n",
    "\n",
    "logger, input_paths = setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe424bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:12,109 - geoworkflow - INFO - Creating AOI for countries: Togo, Ghana, Tanzania, Kenya, Nigeria\n",
      "2025-09-10 19:28:12,111 - geoworkflow.AOIProcessor - INFO - Starting AOIProcessor processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db15fa3932d94f9dacc4c273203ddd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:15,082 - geoworkflow.AOIProcessor - INFO - Loading administrative boundaries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:18,019 - geoworkflow.AOIProcessor - INFO - Filtering 5 countries\n",
      "2025-09-10 19:28:18,022 - geoworkflow.AOIProcessor - INFO - Dissolving country boundaries into single polygon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:19,787 - geoworkflow.AOIProcessor - INFO - Applying 50.0 km buffer\n",
      "2025-09-10 19:28:19,787 - geoworkflow.AOIProcessor - WARNING - Using Africa Albers Equal Area Conic (ESRI:102022) for buffering operations. This projection is optimized for African datasets and may not be accurate for other continents. For non-African data, consider using a more appropriate projected coordinate system (e.g., UTM zones or continental equal-area projections).\n",
      "2025-09-10 19:28:19,788 - geoworkflow.AOIProcessor - INFO - Reprojecting from EPSG:4326 to ESRI:102022 for buffering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:19,833 - geoworkflow.AOIProcessor - INFO - Applying 50.0km (50000.0m) buffer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:30,637 - geoworkflow.AOIProcessor - INFO - Reprojecting back to EPSG:4326\n",
      "2025-09-10 19:28:30,639 - geoworkflow.AOIProcessor - INFO - Saving AOI to /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/geospatial-workflow-project/data/aoi/demo_countries_aoi.geojson\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 19:28:30,658 - geoworkflow.utils.progress_utils - INFO - AOI saved successfully completed: 4/7 items in 15.6s (0.3 items/sec)\n",
      "2025-09-10 19:28:30,659 - geoworkflow.AOIProcessor - INFO - Successfully completed AOIProcessor processing\n",
      "2025-09-10 19:28:30,660 - geoworkflow - INFO - Successfully created AOI with 1 features\n",
      "2025-09-10 19:28:30,660 - geoworkflow - INFO - AOI saved to: /Users/juancheeto/Library/CloudStorage/Box-Box/UrbanStructureStudies/AfricaProject/geospatial-workflow-project/data/aoi/demo_countries_aoi.geojson\n"
     ]
    }
   ],
   "source": [
    "def create_country_aoi(countries: List[str], input_paths: Dict[str, Path], logger) -> Path:\n",
    "    \"\"\"\n",
    "    Create an Area of Interest (AOI) polygon that encompasses the specified countries.\n",
    "    This AOI will be used to clip global datasets to our region of interest, making\n",
    "    subsequent processing faster and more focused.\n",
    "    \n",
    "    The AOI creation process:\n",
    "    - Filters the Africa boundaries file to our target countries\n",
    "    - Dissolves individual country boundaries into a single polygon\n",
    "    - Adds a small buffer to ensure we capture edge effects\n",
    "    - Saves the result for use in clipping operations\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(f\"Creating AOI for countries: {', '.join(countries)}\")\n",
    "    \n",
    "    # Define output path for the combined AOI\n",
    "    aoi_output = project_root / \"data\" / \"aoi\" / \"demo_countries_aoi.geojson\"\n",
    "    aoi_output.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        aoi_config = AOIConfig(\n",
    "            input_file=\"../data/00_source/boundaries/africa_boundaries.geojson\",\n",
    "            country_name_column=\"NAME_0\",  # country name column in geojson above\n",
    "            countries=[\"Togo\", \"Ghana\", \"Tanzania\", \"Kenya\",\"Nigeria\"],\n",
    "            dissolve_boundaries=True,  # Combine all countries into single polygon\n",
    "            buffer_km=50,  # Small buffer to ensure complete data capture\n",
    "            output_file=aoi_output\n",
    "        )\n",
    "        \n",
    "        processor = AOIProcessor(aoi_config)\n",
    "        result = processor.process()\n",
    "        \n",
    "        if not result.success:\n",
    "            raise RuntimeError(f\"AOI creation failed: {result.message}\")\n",
    "            \n",
    "        logger.info(f\"Successfully created AOI with {result.metadata.get('feature_count', 'unknown')} features\")\n",
    "        logger.info(f\"AOI saved to: {aoi_output}\")\n",
    "        \n",
    "        return aoi_output\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create AOI: {e}\")\n",
    "        raise\n",
    "\n",
    "# Define our target countries for the demonstration\n",
    "target_countries = [\"Togo\", \"Ghana\", \"Tanzania\", \"Kenya\",\"Nigeria\"]\n",
    "aoi_file = create_country_aoi(target_countries, input_paths, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d411b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-10 18:29:43,586 - geoworkflow - INFO - Clipping all extracted data using recursive directory processing\n",
      "2025-09-10 18:29:43,588 - geoworkflow - ERROR - Failed to clip extracted data: 1 validation error for ClippingConfig\n",
      "raster_pattern\n",
      "  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ClippingConfig\nraster_pattern\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 2: Clip PM2.5 data to our AOI\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m clipped_pm25_file \u001b[38;5;241m=\u001b[39m \u001b[43mclip_all_extracted_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43maoi_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m, in \u001b[0;36mclip_all_extracted_data\u001b[0;34m(aoi_file, input_paths, logger)\u001b[0m\n\u001b[1;32m      9\u001b[0m clipped_output_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     clipping_config \u001b[38;5;241m=\u001b[39m \u001b[43mClippingConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_root\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m01_extracted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43maoi_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maoi_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipped_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_touched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_visualizations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraster_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disable pattern filtering to avoid the bug\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     processor \u001b[38;5;241m=\u001b[39m ClippingProcessor(clipping_config)\n\u001b[1;32m     22\u001b[0m     result \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mprocess()\n",
      "File \u001b[0;32m~/miniconda3/envs/geoworkflow/lib/python3.10/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ClippingConfig\nraster_pattern\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "def clip_all_extracted_data(aoi_file: Path, input_paths: Dict[str, Path], logger) -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Clip all extracted data (both PM2.5 and AFRICAPOLIS) in one operation using recursive processing.\n",
    "    \n",
    "    This demonstrates the power of GeoWorkflow's unified ClippingProcessor:\n",
    "    - Automatically discovers all raster and vector files in the extracted data directory\n",
    "    - Recursively searches through subdirectories (finds pm25/*.tif and *.geojson)\n",
    "    - Handles different data types (raster vs vector) with the same configuration\n",
    "    - Applies the same AOI clipping to all discovered datasets\n",
    "    - Maintains directory structure in the output\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"Clipping all extracted data using recursive directory processing\")\n",
    "    \n",
    "    # Set up output directory for all clipped data\n",
    "    clipped_output_dir = project_root / \"data\" / \"02_clipped\" / \"demo_all_data\"\n",
    "    clipped_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        clipping_config = ClippingConfig(\n",
    "            input_directory=project_root / \"data\" / \"01_extracted\",\n",
    "            aoi_file=aoi_file,\n",
    "            output_dir=clipped_output_dir,\n",
    "            all_touched=True,  # Include pixels/features that partially overlap the AOI\n",
    "            create_visualizations=False  # Skip visualization for faster processing\n",
    "        )\n",
    "        \n",
    "        processor = ClippingProcessor(clipping_config)\n",
    "        result = processor.process()\n",
    "        \n",
    "        if not result.success:\n",
    "            raise RuntimeError(f\"Data clipping failed: {result.message}\")\n",
    "            \n",
    "        logger.info(f\"Successfully clipped {result.metadata.get('processed_count', 'unknown')} files\")\n",
    "        \n",
    "        # Look for clipped files more flexibly\n",
    "        pm25_files = list(clipped_output_dir.rglob(\"*PM25*.tif\"))\n",
    "        africapolis_files = list(clipped_output_dir.rglob(\"*AFRICAPOLIS*.geojson\"))\n",
    "        \n",
    "        clipped_files = {\n",
    "            \"pm25\": pm25_files[0] if pm25_files else None,\n",
    "            \"africapolis\": africapolis_files[0] if africapolis_files else None\n",
    "        }\n",
    "        \n",
    "        if not clipped_files[\"pm25\"]:\n",
    "            logger.warning(\"No clipped PM2.5 file found\")\n",
    "        if not clipped_files[\"africapolis\"]:\n",
    "            logger.warning(\"No clipped AFRICAPOLIS file found\")\n",
    "            \n",
    "        return clipped_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to clip extracted data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Clip PM2.5 data to our AOI\n",
    "clipped_pm25_file = clip_all_extracted_data(aoi_file, input_paths, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f497a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd722ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_raster_data(clipped_pm25_file: Path, logger) -> Path:\n",
    "    \"\"\"\n",
    "    Align the PM2.5 raster data to ensure consistent spatial properties.\n",
    "    \n",
    "    Raster alignment is crucial because:\n",
    "    - Different data sources often have slightly different grid systems\n",
    "    - Misaligned grids cause errors in zonal statistics calculations\n",
    "    - Alignment ensures pixel boundaries match exactly between datasets\n",
    "    - Standardized grids enable accurate spatial analysis and comparison\n",
    "    \n",
    "    This step resamples the data to a consistent grid while preserving data quality.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"Aligning PM2.5 raster data to standard grid\")\n",
    "    \n",
    "    # Set up output directory for aligned data\n",
    "    aligned_output_dir = project_root / \"data\" / \"03_processed\" / \"demo_aligned\"\n",
    "    aligned_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        alignment_config = AlignmentConfig(\n",
    "            input_directory=clipped_pm25_file.parent,\n",
    "            reference_file=clipped_pm25_file,  # Use PM2.5 as its own reference\n",
    "            output_dir=aligned_output_dir,\n",
    "            resampling_method=\"bilinear\",  # Good balance of speed and accuracy for continuous data\n",
    "            file_pattern=\"*.tif\"\n",
    "        )\n",
    "        \n",
    "        processor = AlignmentProcessor(alignment_config)\n",
    "        result = processor.process()\n",
    "        \n",
    "        if not result.success:\n",
    "            raise RuntimeError(f\"Raster alignment failed: {result.message}\")\n",
    "            \n",
    "        logger.info(f\"Successfully aligned {result.metadata.get('processed_count', 'unknown')} raster files\")\n",
    "        \n",
    "        # Return path to the aligned PM2.5 file\n",
    "        aligned_pm25_file = aligned_output_dir / clipped_pm25_file.name\n",
    "        return aligned_pm25_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to align raster data: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_urban_areas_with_pm25_stats(aligned_pm25_file: Path, clipped_africapolis_file: Path, logger) -> Path:\n",
    "    \"\"\"\n",
    "    Calculate zonal statistics to enrich urban areas with PM2.5 air quality metrics.\n",
    "    \n",
    "    This enrichment process:\n",
    "    - Calculates statistical summaries (mean, max, min, median) of PM2.5 concentrations\n",
    "      for each urban area polygon in the AFRICAPOLIS dataset\n",
    "    - Adds these statistics as new columns to the urban area attribute table\n",
    "    - Enables analysis of air quality patterns across different cities and urban forms\n",
    "    - Creates analysis-ready data that can be used for comparative studies\n",
    "    \n",
    "    The resulting dataset combines urban boundary geometries with quantitative\n",
    "    air quality metrics, supporting research on urban environmental conditions.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"Enriching urban areas with PM2.5 statistics\")\n",
    "    \n",
    "    # Set up output directory for enriched data\n",
    "    enriched_output_dir = project_root / \"data\" / \"04_analysis_ready\"\n",
    "    enriched_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        enrichment_config = StatisticalEnrichmentConfig(\n",
    "            coi_directory=clipped_africapolis_file.parent,\n",
    "            coi_pattern=\"*africapolis*\",  # Pattern to identify our urban boundary file\n",
    "            raster_directory=aligned_pm25_file.parent,\n",
    "            raster_pattern=\"*.tif\",\n",
    "            output_file=enriched_output_dir / \"demo_enriched_urban_areas.geojson\",\n",
    "            statistics=[\"mean\", \"max\", \"min\", \"median\"],  # Key statistical measures\n",
    "            add_area_column=True,  # Include urban area size for analysis\n",
    "            area_units=\"km2\"\n",
    "        )\n",
    "        \n",
    "        processor = StatisticalEnrichmentProcessor(enrichment_config)\n",
    "        result = processor.process()\n",
    "        \n",
    "        if not result.success:\n",
    "            raise RuntimeError(f\"Statistical enrichment failed: {result.message}\")\n",
    "            \n",
    "        logger.info(f\"Successfully enriched {result.metadata.get('original_features', 'unknown')} urban areas\")\n",
    "        logger.info(f\"Added {result.metadata.get('new_columns_added', 'unknown')} statistical columns\")\n",
    "        \n",
    "        enriched_file = enrichment_config.output_file\n",
    "        logger.info(f\"Enriched data saved to: {enriched_file}\")\n",
    "        \n",
    "        return enriched_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to enrich urban areas with statistics: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2b6d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'align_raster_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to examine results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m aligned_pm25_file \u001b[38;5;241m=\u001b[39m \u001b[43malign_raster_data\u001b[49m(clipped_pm25_file, logger)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'align_raster_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def examine_results(enriched_file: Path, logger):\n",
    "    \"\"\"\n",
    "    Examine the final enriched dataset to understand what we've accomplished.\n",
    "    \n",
    "    This examination:\n",
    "    - Loads the enriched dataset and displays basic information\n",
    "    - Shows the new statistical columns that were added\n",
    "    - Provides sample data to illustrate the enrichment results\n",
    "    - Demonstrates how to access the air quality metrics for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"Examining enriched dataset results\")\n",
    "    \n",
    "    try:\n",
    "        # Load the enriched dataset\n",
    "        enriched_gdf = gpd.read_file(enriched_file)\n",
    "        \n",
    "        logger.info(f\"Final dataset contains {len(enriched_gdf)} urban areas\")\n",
    "        logger.info(f\"Dataset columns: {list(enriched_gdf.columns)}\")\n",
    "        \n",
    "        # Identify the new statistical columns (those containing our raster name)\n",
    "        pm25_columns = [col for col in enriched_gdf.columns if 'pm25' in col.lower() or 'cnn' in col.lower()]\n",
    "        \n",
    "        if pm25_columns:\n",
    "            logger.info(f\"PM2.5 statistical columns added: {pm25_columns}\")\n",
    "            \n",
    "            # Show sample statistics\n",
    "            for col in pm25_columns:\n",
    "                if enriched_gdf[col].dtype in ['float64', 'float32', 'int64', 'int32']:\n",
    "                    logger.info(f\"{col}: min={enriched_gdf[col].min():.2f}, \"\n",
    "                              f\"max={enriched_gdf[col].max():.2f}, \"\n",
    "                              f\"mean={enriched_gdf[col].mean():.2f}\")\n",
    "        \n",
    "        # Show a sample of the enriched data\n",
    "        logger.info(\"Sample of enriched urban areas:\")\n",
    "        sample_cols = ['ISO', 'COUNTRY_NA'] + pm25_columns[:2] + ['area_km2']\n",
    "        available_cols = [col for col in sample_cols if col in enriched_gdf.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            sample_data = enriched_gdf[available_cols].head(3)\n",
    "            for idx, row in sample_data.iterrows():\n",
    "                logger.info(f\"  Urban area {idx}: \" + \n",
    "                          \", \".join([f\"{col}={row[col]}\" for col in available_cols]))\n",
    "        \n",
    "        logger.info(\"=== Workflow demonstration completed successfully! ===\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to examine results: {e}\")\n",
    "        raise\n",
    "\n",
    "aligned_pm25_file = align_raster_data(clipped_pm25_file, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82180609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute the complete AfricaPolis workflow demonstration.\n",
    "\n",
    "This main function orchestrates the entire data processing pipeline:\n",
    "1. Sets up the processing environment and verifies input data\n",
    "2. Creates an Area of Interest for our target countries  \n",
    "3. Clips global datasets to our region of interest\n",
    "4. Aligns raster data to ensure spatial consistency\n",
    "5. Enriches urban areas with air quality statistics\n",
    "6. Examines the final results\n",
    "\n",
    "Each step builds on the previous ones, demonstrating how raw geospatial\n",
    "data transforms into analysis-ready enriched datasets.\n",
    "\"\"\"\n",
    "\n",
    "# Define our target countries for the demonstration\n",
    "target_countries = [\"Togo\", \"Ghana\", \"Tanzania\", \"Kenya\"]\n",
    "\n",
    "try:\n",
    "    # Initialize the processing environment\n",
    "    logger, input_paths = setup_environment()\n",
    "    \n",
    "    # Step 1: Create Area of Interest for target countries\n",
    "    aoi_file = create_country_aoi(target_countries, input_paths, logger)\n",
    "    \n",
    "    # Step 2: Clip PM2.5 data to our AOI\n",
    "    clipped_pm25_file = clip_all_extracted_data(aoi_file, input_paths, logger)\n",
    "    \n",
    "    # Step 3: Clip AFRICAPOLIS data to our AOI\n",
    "    clipped_africapolis_file = clip_africapolis_data(aoi_file, input_paths, logger)\n",
    "    \n",
    "    # Step 4: Align raster data for consistent processing\n",
    "    aligned_pm25_file = align_raster_data(clipped_pm25_file, logger)\n",
    "    \n",
    "    # Step 5: Enrich urban areas with PM2.5 statistics\n",
    "    enriched_file = enrich_urban_areas_with_pm25_stats(aligned_pm25_file, clipped_africapolis_file, logger)\n",
    "    \n",
    "    # Step 6: Examine the final results\n",
    "    examine_results(enriched_file, logger)\n",
    "    \n",
    "    print(\"\\n🎉 Demonstration completed successfully!\")\n",
    "    print(f\"📁 Check the enriched results at: {enriched_file}\")\n",
    "    print(\"📊 The urban areas now include PM2.5 air quality statistics\")\n",
    "    print(\"🔍 Review the log file at: notebooks/demo_processing.log\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Demonstration failed: {e}\")\n",
    "    print(\"💡 Check the log file for detailed error information\")\n",
    "    print(\"🤖 Try asking Claude: 'My workflow failed with this error: [paste error message]'\")\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoworkflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
